<!DOCTYPE html>
<html lang = "en">
    <head>
        <meta charset="UTF-8">
        <title> DSC180B Face Mask Detector </title> 
        <link rel="stylesheet" href="styles.css">
    </head>

    <body>
        <nav id = 'navbar'>
            <a href = "#intro" class = "button">Introduction</a>
            <a href = "#data" class = 'button'> Data </a>
            <a href = "#mehtod" class = "button"> Methodology</a>
            <a href = "#result" class = "button">Result</a>
            <a href = "#demo" class = "button"> Demo </a>
            <a href = "#conclusion" class = "button">Conclusion</a>
            <a href = "#user" class = "button">User Manual</a>
            <a href = "#about" class = "button"> About Us </a>
        </nav>
        <header>
            <div id = 'header'>
                <h1 id = "title"> Face Mask Detection with Explainable Artificial Intelligence </h1>
            </div>
        </header>

        <section>
            <div id = "intro" class = "content">
                <h3> Why do you need a face mask detector? </h3> 
                <div class = "flexbox">
                    <div class = "container" id = 'covidtrend'>
                        <!--img src = "data/covid_trend.JPG", alt = 'covid-trend.jpg' width = 100% height = auto -->
                        <iframe src="https://ourworldindata.org/grapher/total-cases-covid-19?tab=map" width="100%" height="600px"></iframe>
                    </div> 
                    <div id = "introscript" class = "container">
                        <h4> Challenges Under the Pandemic </h4> 
                        <p> The United States is the country with the most amount of cases recorded of SARS-COV19. 
                            Even though the CDC recommends that the public wear a mask when in close contact with others 
                            to prevent further spread, many individuals are still not following protocol. Many businesses are 
                            taking a hefty loss throughout these times while also being the ones that must enforce these temporary 
                            mask policies for the safety of the employees and customers to protect what business they have left. 
                            Although its one thing to wear a mask, its also important to be able to distinguish between wearing a 
                            mask correctly or not to maximize the prevention of either catching or spreading the disease further.</p>
                        
                        <h4> How do we resolve this challenge? </h4>
                        <p> In response to these chanllegnes, we created a face mask detector that would not only detect the presence 
                            of a mask but also evaluate if the person is wearing the mask correctly! This face mask detector could help 
                            business owners monitor and ensure customers wearing a mask at all time inside the store. More importantly, 
                            it could help to protect you, your employees, and your customers' safety. Please read more to learn about our
                             face mask detector. </p>
                    </div>
                </div>
            </div>

            <div id = "data" class = "content">
                <h3> Dataset: MaskedFace-Net </h3>
                <p > 
                    Our training dataset makes our model unique. Prior to developing our face mask detector, we researched many currently existing 
                    face mask detectors developed by other teams. We found the common disadvantage between these models is the lack of sufficient 
                    training data. Moreover, many face mask detectors are restricted to binary classification since their dataset only contains "mask" 
                    and "no-mask" images. A more diverse dataset that contains images of people wearing a mask, no wearing a mask, and wearing 
                    a mask incorrectly is required to achieve our goal. And, we overcame this issue by using the MaskedFace-Net dataset made available on Kaggle.
                </p>
                <a href = "https://www.kaggle.com/sheldonsebastian/maskednet-flicker-faces"> Click to access dataset </a>
                <h4 style="color: black"> Sample Images </h4>
                <div class = "flexbox">
                    <div>
                        <img src = "data/00021_Mask.jpg" alt = "mask.jpg" class = 'demoimg'>
                        <p> Correctly Masked </p>
                    </div>
                    <div>
                        <img src = "data/20060_Mask_Chin.jpg" alt = "incorrect_mask.jpg" class = 'demoimg'>
                        <p> Incorrectly Masked </p>
                    </div>
                    <div>
                        <img src = "data/50020.jpg" atl = 'no-mask.jpg' class = "demoimg">
                        <p> Missing Mask </p>
                    </div>
                </div>

                <h3> A Reliable Dataset Makes a Good Detector </h3> 
                <p>
                    The dataset that we trained our model on is MaskedFace-Net. 
                    In this dataset, we have over 50,000 headshot images broken into three categories including people wearing a mask correctly, 
                    incorrectly, or not at all. These 50,000 images are then split into three datasets, training, validation, and test, which 
                    is included in a breakdown of our dataset seen below. The breakdown also reveals that each of these categories are evenly 
                    distributed being roughly 1/3rd of each dataset respectively.Having a large dataset which is also labelled to deal with the 
                    problem at hand and also fairly evenly distributed made this dataset stand out much more than other datasets. </p>
                <div id = "piechart" class = "flexbox">
                    <div>
                        <img src = "data/databreakdown_pie.png" alt = "data_breakdown.png" class = 'pie'>
                        <p> Dataset Breakdown </p>
                    </div>
                    <div>
                        <img src = "data/trainingbreakdown_pie.png" alt = "train_breakdown.png" class = 'pie'>
                        <p> Training Set Breakdown </p>
                    </div>
                </div>

                <div id = "piechart" class = "flexbox">
                    <div>
                        <img src = "data/validationbreakdown_pie.png" atl = 'validation_breakdown.png' class = 'pie'>
                        <p> Validation Set Breakdown </p>
                    </div>
                    <div>
                        <img src = "data/testingbreakdown_pie.png" atl = 'testing_breakdown.png' class = 'pie'>
                        <p> Testing Set Breakdown </p>
                    </div>
                </div>
            </div>

            <div id = "method" class = "content">
                <h3> Our Product </h3>
                <div id = "methodbox" class = "flexbox">
                    <div class = "container">
                        <h4> Convolutional Neural Network </h4>
                        <p>Our face mask detector uses a model called a pre-trained ResNet50, which is a type of convolutional neural network that is 50 layers deep. 
                            ResNet50 is a powerful neural network that is able to classify images into categories. The structure of ResNet50 is made up of two parts: 
                            the first part is feature extraction, where the model learns features in an image, and the second part is classification, where the model
                             makes a prediction based on the features it has learned during the first phase. In our case, we fine-tune a pre-trained ResNet50 for our 
                             task. This means that during training, we donâ€™t change how the model learns features. Instead, we only train how model makes prediction.
                              We believe this is a feasible approach to achieving high accuracy.</p>
                        <img src = "data/resnet.png">
                    </div>
                    <div class = "container">
                        <h4> GradCam </h4>
                        <p> Grad-CAM is a type of Explainable AI (XAI) method that aims to identify what features does the model rely on in predicting the output. 
                            The output of Grad-CAM is a heat map that will highlight the region where the model believes is important. 
                            The heat map is generated by retrieving information from the last convolutional layer. The information is also known as feature maps, 
                            which represent learned features and are important for model to predict output. The feature maps are passed into the classification layer to determine a weight for each feature. 
                            Then this importance is visualized by calculating the weighted sum of each feature and through an activation function ReLU</p>
                        <img src = "data/gradcam.png" width = 80% height = auto>
                    </div>
                    <div class = "container">
                        <h4> Intergrated Gradient</h4>
                        <p>We also use Integrated Gradient to ensure our model is behaving the way we want it to. 
                            Integrated Gradient is another visualizing method that will assign a score to each feature given an 
                            input and a neural network function. Below is a formula for obtaining integrated gradient:
                        </p>
                        <img src = "data/intergrated.png">
                        <p>We can divide the formula into 3 steps: <br>
                            1. Compute the gradient of function output with respect to feature I <br>
                            2. Integrated over the gradients to avoid saturation problem (meaning some features high have small gradients even if they are important) <br>
                            3. Multiply the difference between baseline input (which is a blank or black image used to represent the absence of feature) and original input to get the feature importance score, which is integrated gradient. <br>
                        </p>
                    </div>
                </div>
            </div>
    
            <div id = "result" class = "content">
                <h3> Result </h3> 
                <div id = "resultbox" class = "flexbox">
                    <div>
                        <h4> Under CNN Model?  </h4>
                        <p> 
                            After training our model on the training dataset, we then trained the model on our Validation set and found an accuracy measurement of 95%.
                             We also then tried retraining our model onto the training dataset alongside training the model onto the test datasets and discovered accuracy 
                             measurements of 88% and 95% respectively. Although its slightly concerning that our model performed worse when retraining on itself (primarily 
                             due to overfitting errors, which we address in the report) our findings reveal that our model performs fairly well on unseen data 
                             (both the Validation and Test sets).
                        </p>
                        <img src = "data/result1.jpg">
                    </div> 
                    <div>
                        <h4> Under Grad-CAM? </h4>
                        <p> Since Grad-CAM is purely for visualization purposes, we decided to provide an example case when running the model on the validation set. 
                            We will briefly go over each image, but if youâ€™re more curious, check out our report where we go over this algorithm in more detail. 
                            The first image is a heatmap generated by Grad-CAM. The mask is the class/object of interest in our model and although Grad-CAM doesnâ€™t provide us labels, 
                            this image is most likely to be classified as correctly worn due to the full coverage of the face. The second image is generated with Grad-CAM and 
                            Guided Backpropagation. What we see in this image are the highlighted pixels of the original image of our model alongside some extra highlighting 
                            due to the findings of Grad-CAM, which reveals some importance to the head, but has the most important pixels around the mask. The last image is generated 
                            solely with Guided Backpropagation. This image reveals the areas of interest through highlighting the pixels of the original image in this altered variation, 
                            which in this case reveals a headshot.
                        </p>
                        <div class = "flexbox" id = "result-viz">
                            <div>
                                <img src = "data/result_viz1.png">
                                <img src = "data/result_viz2.png">
                                <img src = "data/result_viz3.png">
                            </div>
                        </div>
                    </div>
                    <div>
                        <h4>Under Integrated Gradient?</h4> 
                        <p>Likewise, since Integrated Gradients is purely for visualization purposes, we decided to provide an example case when running the model on the validation set. 
                            Again, we will briefly go over each image, but if youâ€™re more curious, check out our report where we go over this algorithm in more detail.  
                            In this example, we see that Integrated Gradients reveals that there are two important individual features/objects, the first being a mask and the second being a face. 
                            The mask is relatively clearer in the second image, mostly because of the importance of highlighting the entire face when detecting it as the object.
                        </p>
                        <img src = "data/result_viz4.png">
                    </div>
                </div>
            </div>

            <div id = "demo" class = "content">
                <h3>Face Mask Detector and Visualization Tool Kit Demo</h3> 
                <p> We prepared three demos for you in this section. Please click on the images below to see the associated ouputs. </p>
                <h4> Input Image </h4>
                <div id = "demo-input" class = "flexbox">
                    <form id = "demo-form">
                        <input type = "image" src = "data/case1.jpg" value = "case1" onclick="render_demo('case1');return false;">
                        <input type = "image" src = "data/case2.jpg" value = "case2" onclick="render_demo('case2');return false;">
                        <input type = 'image' src = "data/case3.jpg" value = "case3" onclick="render_demo('case3');return false;">
                    </form>
                </div>
                <div id = "demo-output" class = "flexbox">
                    <div id = "col1" class = 'flexbox'>
                        <div id = 'original'>
                            <h4> Original Image </h4>
                            <img id = "original_image" src = "data/rendering-small.jpg">
                        </div>
                        <div id = 'gradcam'>
                            <h4>Gradcam Output</h4> 
                            <img id = "gradcam_output" src = "data/rendering-small.jpg">
                        </div>
                    </div>
                    <div id = 'col2'>
                        <div>
                            <h4> Classification: <span id = 'classification'> ??? </span></h4>
                        </div>
                        <div id = 'int-grad'>
                            <h4>Intergrated Gradient Output</h4> 
                            <img id = "ig_output" src = "data/rendering-big.jpg">
                        </div>
                    </div>
                </div>
            </div>
    
            <div id = "conclusion" class = "content">
                <h3> Conclusion </h3> 
                    <div>
                        <p> Our product addressed a current concern shared by people
                            across the world and point out a common bad habit practiced
                            by the general public, which is wearing mask incorrectly
                            and has jeopardized a lot of business. We attempted to
                            mitigate this issue by creating a face mask detector that
                            will help business owners comply with laws and ensure the
                            survival of their business. Moreover, we created the face mask
                            detector to protect business owners, employees,
                            and customers' safety and health during the pandemic. 
                            Our approach to building such a
                            face mask detector is successful and is proven to work in the
                            intended way. We hope that more face mask detectors can be
                            implemented so that business owner can survive in this rather
                            difficult time and that people can protect not only themselves
                            but also others.
                        </p>
                    </div>
                    <div>
                        <img src = "data/mask.JPG" width = 45%>
                    </div>
            </div>

            <div id = "user" class = "content">
                <h3>User Manual</h3> 
                <p>If you're interested in our product, please visit our github repository. <br>
                    You can access the Face Mask Detector and Visualization Tool Kit by cloning this repository. <br>
                    Please follow instructions under the Readme section to set up the working enviornment. <br>
                    Please contact us if you encountered any issues with installation. <br>
                    Thank you so much for your interest in our product! Looking forward to hearing your feedback!
                </p> 
                <a href = "https://github.com/gatran/DSC180B-Face-Mask-Detection"> <img src = 'data/github.jpg' width = 30%></a>
                <p> <a href = "https://github.com/gatran/DSC180B-Face-Mask-Detection"> GitHub</a> </p>
            </div>

            <div id = "about" class = "content">
                <h3> About Us </h3>
                <div class = "flexbox">
                    <div class = "container">
                        <h4>Gavin Tran</h4>
                        <p> UCSD 4th Year Data Science</p>
                        <p> Contact: gatran@ucsd.edu</p>
                    </div>
                    <div class = "container">
                        <h4>Athena Liu</h4>
                        <p> UCSD 4th Year Data Science</p>
                        <p> Contact: atl074@ucsd.edu</p>
                    </div>
                    <div class = "container">
                        <h4>Jerry Lin</h4>
                        <p> UCSD 4th Year Data Science</p>
                        <p> Contact: chl820@ucsd.edu</p>
                    </div>
                </div>
            </div>
        </section>
    </body>
    <script src="main.js"></script>
    <footer>

    </footer>
</html>